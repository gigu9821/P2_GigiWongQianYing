{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **FIQA Data Preprocessing**"
      ],
      "metadata": {
        "id": "GzD7SLfisWAQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 1. Mount Google Drive**"
      ],
      "metadata": {
        "id": "ezcGYLaSrg-A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1UWWvegrdp3"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Google Drive mounted successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Google Drive mount failed: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 2. Load FIQA Dataset and Extract Targets**"
      ],
      "metadata": {
        "id": "lGNnSS3krmeA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import re\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "\n",
        "# Base path for all files\n",
        "base_path = \"/content/drive/My Drive/P2/\"\n",
        "\n",
        "# Path to FIQA dataset\n",
        "fiqa_path = base_path + \"fiqa_1.csv\"\n",
        "\n",
        "# Load FIQA data\n",
        "df_fiqa = pd.read_csv(fiqa_path)\n",
        "\n",
        "# Extract unique targets (tickers or entity names)\n",
        "tickers = df_fiqa[\"target\"].astype(str).str.strip().unique()\n",
        "\n",
        "print(f\"Total number of unique targets found: {len(tickers)}\")\n",
        "print(tickers.tolist())"
      ],
      "metadata": {
        "id": "9Y41qqGPrk9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 3. Automatically Retrieve Sector Information Using Yahoo Finance**"
      ],
      "metadata": {
        "id": "jG2KRdqXrsxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Store ticker-sector mapping\n",
        "sector_data = []\n",
        "\n",
        "print(\"\\nFetching sector information automatically...\\n\")\n",
        "\n",
        "for ticker in tickers:\n",
        "    ticker_clean = ticker.upper()\n",
        "\n",
        "    try:\n",
        "        stock = yf.Ticker(ticker_clean)\n",
        "        sector = stock.info.get(\"sector\", None)\n",
        "\n",
        "        if sector is None:\n",
        "            print(f\"{ticker_clean}: sector not found, set to General\")\n",
        "            sector = \"General\"\n",
        "        else:\n",
        "            print(f\"{ticker_clean}: {sector}\")\n",
        "\n",
        "        sector_data.append({\"ticker\": ticker_clean, \"sector\": sector})\n",
        "\n",
        "    except Exception:\n",
        "        print(f\"{ticker_clean}: fetch failed, set to General\")\n",
        "        sector_data.append({\"ticker\": ticker_clean, \"sector\": \"General\"})\n",
        "\n",
        "    time.sleep(0.5)"
      ],
      "metadata": {
        "id": "GA9fvzSKrtwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 4. Save Initial Ticker–Sector Mapping**"
      ],
      "metadata": {
        "id": "4tPqzwbbrwlO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save initial mapping result\n",
        "output_path = base_path + \"ticker_sector.csv\"\n",
        "df_sector = pd.DataFrame(sector_data)\n",
        "df_sector.to_csv(output_path, index=False)\n",
        "\n",
        "print(\"\\nInitial ticker_sector.csv generated:\")\n",
        "print(output_path)"
      ],
      "metadata": {
        "id": "7GhLnastrvac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 5. Load Mapping File and Define Manual Sector Corrections**"
      ],
      "metadata": {
        "id": "yv-bTs6Mr0Q2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Load previously generated ticker-sector file\n",
        "df_old = pd.read_csv(base_path + \"ticker_sector.csv\")\n",
        "\n",
        "print(\"\\nPreview of original mapping data:\")\n",
        "print(df_old.head())\n",
        "\n",
        "# Manual sector mapping dictionary\n",
        "manual_map = {\n",
        "    #original\n",
        "    \"BBRY\":\"Technology\",\"HK\":\"Energy\",\"YHOO\":\"Technology\",\"P\":\"Communication Services\",\n",
        "    \"BERKSHIRE HATHAWAY INC.\":\"Financial Services\",\"SAMARCO\":\"Basic Materials\",\"SPY\":\"Financial Services\",\n",
        "    \"PCLN\":\"Consumer Cyclical\",\"ASOS PLC\":\"Consumer Cyclical\",\"USO\":\"Energy\",\"GLD\":\"Basic Materials\",\n",
        "    \"SANOFI\":\"Healthcare\",\"WYN\":\"Consumer Cyclical\",\"INTEGRATED SILICON SOLUTION\":\"Technology\",\n",
        "    \"SAB MILLER\":\"Consumer Defensive\",\"KINGFISHER\":\"Consumer Cyclical\",\"QQQ\":\"Financial Services\", \"STANCHART\":\"Financial Services\",\n",
        "    \"ASTRAZENECA\":\"Healthcare\",\"FB\":\"Communication Services\",\"RBS\":\"Financial Services\",\"GPS\":\"Consumer Cyclical\",\n",
        "    \"ATVI\":\"Communication Services\",\"INTERCONTINENTAL\":\"Consumer Cyclical\",\"BIOC\":\"Healthcare\",\"BUNZL\":\"Industrials\",\n",
        "    \"ZSL\":\"Financial Services\",\"EXXONMOBIL\":\"Energy\",\"BHP BILLITON\":\"Basic Materials\",\"CHINA MERCHANTS GROUP\":\"Basic Materials\",\n",
        "    \"GERMANWINGS\":\"Industrials\",\"ROYAL DUTCH SHELL\":\"Energy\",\"SAUDI ARAMCO\":\"Energy\",\"VMW\":\"Technology\",\n",
        "    \"SAINSBURY\":\"Consumer Defensive\",\"TESCO\":\"Consumer Defensive\",\"YNDX\":\"Communication Services\",\n",
        "    \"CNDO\":\"Healthcare\",\"VVUS\":\"Healthcare\",\"SABMILLER\":\"Consumer Defensive\",\"ROYAL MAIL\":\"Industrials\",\n",
        "    \"EASYJET\":\"Consumer Cyclical\",\"M&S\":\"Consumer Cyclical\",\"L&G\":\"Financial Services\",\"ENDP\":\"Healthcare\",\n",
        "    \"ASHTEAD\":\"Industrials\",\"XLE\":\"Energy\",\"STANDARD CHARTERED\":\"Financial Services\",\n",
        "    \"QCOR\":\"Healthcare\",\"SHIRE\":\"Healthcare\",\"QIHU\":\"Technology\",\"HIKMA\":\"Healthcare\",\n",
        "    \"SENSEX\":\"Financial Services\",\"NOVARTIS\":\"Healthcare\",\"LLOYDS\":\"Financial Services\",\"LUFTHANSA\":\"Industrials\",\n",
        "    \"BONE\":\"Healthcare\",\"MORRISSONS\":\"Consumer Defensive\",\"JNUG\":\"Financial Services\",\"GLAXOSMITHKLINE\":\"Healthcare\",\n",
        "    \"TSPT\":\"Healthcare\",\"STARWOOD\":\"Consumer Cyclical\",\"TZA\":\"Financial Services\",\"RIO TINTO\":\"Basic Materials\",\n",
        "    \"HSC\":\"Industrials\",\"SLW\":\"Basic Materials\",\"SHELL\":\"Energy\",\"LONDON STOCK EXCHANGE\":\"Financial Services\",\n",
        "    \"FIO\":\"Technology\",\"GLENCORE\":\"Basic Materials\",\"ZAGG\":\"Technology\",\"BARCLAYS\":\"Financial Services\",\n",
        "    \"SPORTS DIRECT\":\"Consumer Cyclical\",\"HCP\":\"Healthcare\",\"ALTR\":\"Technology\",\"INSIGHT\":\"Technology\",\n",
        "    \"CAFN\":\"Technology\",\"JNPR\":\"Technology\",\"AER LINGUS\":\"Industrials\",\"ABERDEEN AM\":\"Financial Services\",\n",
        "    \"TALKTALK\":\"Communication Services\",\"CNPC\":\"Energy\",\"FRIENDS LIFE\":\"Financial Services\",\"PRUDENTIAL\":\"Financial Services\",\n",
        "    \"BWLD\":\"Consumer Cyclical\",\"LONMIN\":\"Basic Materials\",\"EFUT\":\"Technology\",\"TWTR\":\"Communication Services\",\n",
        "    \"XLF\":\"Financial Services\",\"RDC\":\"Energy\",\"SLV\":\"Basic Materials\",\"LEHMAN\":\"Financial Services\",\"PEARSON\":\"Communication Services\",\n",
        "    \"HOME RETAIL GROUP\":\"Consumer Cyclical\",\"STATOIL\":\"Energy\",\"CHRM\":\"Healthcare\",\"PERSSIMON\":\"Consumer Cyclical\",\n",
        "    \"CAIXABANK\":\"Financial Services\",\"RANGOLD\":\"Basic Materials\",\"DIXONS CARPHONE\":\"Consumer Cyclical\",\n",
        "    \"DEBENHAMS\":\"Consumer Cyclical\",\"SODA\":\"Consumer Defensive\",\"SKS\":\"Consumer Cyclical\",\n",
        "    \"SOX\":\"Financial Services\",\"SKH\":\"Healthcare\",\"BURBERRY\":\"Consumer Cyclical\",\"ZNGA\":\"Technology\",\"CENTRICA\":\"Utilities\",\n",
        "    \"LAZADA\":\"Consumer Cyclical\",\"X\":\"Basic Materials\",\"HOME RETAIL\":\"Consumer Cyclical\",\"MEGGITT\":\"Industrials\",\n",
        "    \"BOBE\":\"Consumer Cyclical\",\"THETRAINLINE.COM\":\"Communication Services\",\"BERKSHIRE\":\"Financial Services\",\n",
        "    \"JOHNSON MATTHEY\":\"Basic Materials\",\"GLAXO\":\"Healthcare\",\"ENTERTAINMENT ONE\":\"Communication Services\",\n",
        "    \"ZURICH INSURANCE\":\"Financial Services\",\"SDS\":\"Financial Services\",\"TOWERGATE\":\"Financial Services\",\"GMCR\":\"Consumer Defensive\",\n",
        "    \"AGU\":\"Basic Materials\",\"ARIA\":\"Healthcare\",\"TESCO PLC\":\"Consumer Defensive\",\"DWA\":\"Financial Services\",\"AVIVA\":\"Financial Services\",\n",
        "    \"DIAGEO\":\"Consumer Defensive\",\"ZS PHARMA\":\"Healthcare\",\"WEIR\":\"Industrials\",\"VALEANT\":\"Healthcare\",\n",
        "    \"KRAFT\":\"Consumer Defensive\",\"GOL\":\"Consumer Cyclical\",\"STANDARD BANK\":\"Financial Services\",\"AXDX\":\"Healthcare\",\n",
        "    \"KINDER MORGAN\":\"Energy\",\"DAIICHI SANKYO\":\"Healthcare\",\"LNKD\":\"Technology\",\"UBNT\":\"Technology\",\n",
        "    \"BALFOUR BEATTY PLC\":\"Industrials\",\"G4S\":\"Industrials\",\"CTRP\":\"Consumer Cyclical\",\"ARM HOLDINGS\":\"Technology\",\n",
        "    \"AEGN\":\"Industrials\",\"IMRS\":\"Healthcare\",\"UUP\":\"Financial Services\",\"MEDIACITYUK\":\"Communication Services\",\"MILLERCOORS\":\"Consumer Defensive\",\n",
        "    \"DIALOG\":\"Technology\",\"PWC\":\"Financial Services\",\"DET NORSKE\":\"Energy\",\"SEVERN TRENT\":\"Utilities\",\n",
        "    \"PERSIMMON\":\"Consumer Cyclical\",\"SPX\":\"Industrials\",\"ACTELION\":\"Healthcare\",\"EXXON\":\"Energy\",\"NQ\":\"Technology\",\n",
        "    \"REED ELSEVIER\":\"Communication Services\",\"OLD MUTUAL\":\"Financial Services\",\"ASDA\":\"Consumer Defensive\",\n",
        "    \"OCN\":\"Financial Services\",\"RENN\":\"Technology\",\"PETROFAC\":\"Energy\",\"ITV\":\"Communication Services\",\n",
        "    \"SOPHOS\":\"Technology\",\"UNILEVER\":\"Consumer Defensive\",\"CITI\":\"Financial Services\",\"BXS\":\"Financial Services\",\n",
        "    \"BLINKBOX\":\"Communication Services\",\"IWM\":\"Financial Services\",\"PERRIGO\":\"Healthcare\",\"BBBY\":\"Consumer Defensive\",\n",
        "    \"SHOR\":\"Consumer Cyclical\",\"AMCN\":\"Communication Services\",\"MFLX\":\"Technology\",\"HZNP\":\"Healthcare\",\n",
        "    \"STANDARD LIFE\":\"Financial Services\",\"BG GROUP\":\"Energy\",\"CELG\":\"Healthcare\",\"OMNIS PHARMACEUTICALS\":\"Healthcare\",\n",
        "    \"PRGN\":\"Healthcare\",\"SKX\":\"Consumer Cyclical\",\"INTERTEK\":\"Industrials\",\"IMPERIAL TOBACCO\":\"Consumer Defensive\",\n",
        "    \"CENTRICA PLC\":\"Utilities\",\"RYANAIR\":\"Industrials\",\"SINA\":\"Communication Services\",\"RXII\":\"Healthcare\",\n",
        "    \"MCP\":\"Basic Materials\",\"TAKEDA\":\"Healthcare\",\"ACOM\":\"Technology\",\"ONEMAIN\":\"Financial Services\",\n",
        "    \"SMH\":\"Financial Services\",\"LAND SECURITIES\":\"Real Estate\",\"FAZ\":\"Financial Services\",\"MR BRICOLAGE\":\"Consumer Cyclical\",\n",
        "    \"SCHRODERS\":\"Financial Services\",\"FXE\":\"Financial Services\",\"GTAT\":\"Technology\",\"INOVIO\":\"Healthcare\",\"SONC\":\"Consumer Cyclical\",\n",
        "    \"TYC\":\"Industrials\",\"HARGREAVES LANSDOWN\":\"Financial Services\",\"DEERE\":\"Industrials\",\n",
        "    \"BRITISH AMERICAN TOBACCO\":\"Consumer Defensive\",\"LEMANN\":\"Financial Services\",\"UVXY\":\"Financial Services\",\n",
        "    \"MWW\":\"Industrials\",\"VERIZON\":\"Communication Services\",\"SWY\":\"Consumer Defensive\",\"SAB\":\"Consumer Defensive\",\n",
        "    \"CERN\":\"Healthcare\",\"SAVE\":\"Consumer Cyclical\",\"CTXS\":\"Technology\",\"CREDIT SUISSE\":\"Financial Services\",\n",
        "    \"WOLSELEY\":\"Industrials\",\"KIOR\":\"Basic Materials\",\"WX\":\"Healthcare\",\"COUTTS\":\"Financial Services\",\n",
        "    \"GREENE KING\":\"Consumer Defensive\",\"BAT\":\"Consumer Defensive\",\"JNK\":\"Financial Services\",\"DEUTSCHE BÖRSE\":\"Financial Services\",\n",
        "    \"CREE\":\"Technology\",\"ATHN\":\"Technology\",\"M&G\":\"Financial Services\",\"INTERTEK GROUP\":\"Industrials\",\n",
        "    \"YANG\":\"Financial Services\",\"GKN\":\"Industrials\",\"COH\":\"Consumer Cyclical\",\"NSM\":\"Financial Services\",\"SPPI\":\"Healthcare\",\n",
        "    \"HDSI\":\"Technology\",\"WILSHIRE BANCORP\":\"Financial Services\",\"NIKKEI\":\"Financial Services\",\"RSOL\":\"Energy\",\n",
        "    \"WELLS FARGO\":\"Financial Services\",\"PKT\":\"Technology\",\"RNN\":\"Healthcare\",\"DISH\":\"Communication Services\",\n",
        "    \"RAD\":\"Consumer Defensive\",\"MXWL\":\"Technology\",\"UGAZ\":\"Financial Services\",\"NIHD\":\"Communication Services\",\"WAC\":\"Financial Services\",\n",
        "    \"HORIZONTE\":\"Basic Materials\",\"GAZPROM\":\"Energy\",\"NUGT\":\"Financial Services\",\"SSRI\":\"Basic Materials\",\n",
        "    \"JV PARTNER\":\"Industrials\",\"XLB\":\"Energy\",\"YOKU\":\"Communication Services\",\"KIPA\":\"Consumer Defensive\",\n",
        "    \"BRCM\":\"Technology\",\"AUTO TRADER\":\"Consumer Cyclical\",\"ASTX\":\"Healthcare\",\"FMCN\":\"Communication Services\",\n",
        "    \"WHITBREAD\":\"Consumer Cyclical\",\"AXA\":\"Financial Services\",\"KITD\":\"Communication Services\",\n",
        "    \"LEGAL & GENERAL\":\"Financial Services\",\"BERKSHIRE HATHAWAY\":\"Financial Services\",\n",
        "    \"DBO\":\"Financial Services\",\"ELN\":\"Healthcare\",\"DARA\":\"Healthcare\",\"OCWEN\":\"Financial Services\",\n",
        "\n",
        "    #update\n",
        "    \"MORRISONS\": \"Consumer Defensive\",\n",
        "    \"SYMC\": \"Technology\",\n",
        "    \"DEUTSCHE BÃ\\x83Â¶RSE\": \"Financial Services\",\n",
        "    \"IBB\": \"Healthcare\",\n",
        "    \"TULLOW OIL\": \"Energy\"\n",
        "}"
      ],
      "metadata": {
        "id": "KOlR6PFtr17a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 6. Apply Smart Sector Filling Logic**"
      ],
      "metadata": {
        "id": "CND8xQ2psKL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Smart sector filling logic\n",
        "def smart_fill(row):\n",
        "    current_sec = row['sector']\n",
        "    ticker = str(row['ticker']).strip()\n",
        "\n",
        "    # Keep existing valid sector\n",
        "    if pd.notna(current_sec) and str(current_sec).lower() != \"general\":\n",
        "        return current_sec\n",
        "\n",
        "    # Try exact match\n",
        "    if ticker in manual_map:\n",
        "        return manual_map[ticker]\n",
        "\n",
        "    # Try uppercase match\n",
        "    elif ticker.upper() in manual_map:\n",
        "        return manual_map[ticker.upper()]\n",
        "\n",
        "    # Fallback\n",
        "    return \"General\"\n",
        "\n",
        "print(\"Applying manual sector corrections...\")\n",
        "df_old[\"sector\"] = df_old.apply(smart_fill, axis=1)"
      ],
      "metadata": {
        "id": "wJmF9LiIr5Ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 7. Final Fallback Strategy for Unmatched Sectors**"
      ],
      "metadata": {
        "id": "1YX_cy6EsOZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify rows still labeled as General\n",
        "unknown_mask = df_old[\"sector\"] == \"General\"\n",
        "\n",
        "# Extract unique unmatched tickers\n",
        "unknown_tickers = df_old.loc[unknown_mask, \"ticker\"].unique()\n",
        "unknown_count = unknown_tickers.shape[0]\n",
        "\n",
        "if unknown_count > 0:\n",
        "    print(f\"Warning: {unknown_count} tickers still unmatched. Assigning default sector.\")\n",
        "\n",
        "    print(\"Unmatched tickers:\")\n",
        "    for t in unknown_tickers:\n",
        "        print(\" -\", t)\n",
        "\n",
        "    # Assign default sector\n",
        "    df_old.loc[unknown_mask, \"sector\"] = \"Financial Services\"\n",
        "\n",
        "else:\n",
        "    print(\"All tickers have been assigned a sector.\")"
      ],
      "metadata": {
        "id": "cAYDQOursMX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 8. Save Final Sector Mapping**"
      ],
      "metadata": {
        "id": "5LSr-gj7sRCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save final sector mapping\n",
        "save_path = \"/content/drive/My Drive/P2/final_ticker_sector3.csv\"\n",
        "df_old.to_csv(save_path, index=False)\n",
        "\n",
        "print(f\"Final sector mapping saved to: {save_path}\")"
      ],
      "metadata": {
        "id": "Vc8QUbzTsQqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 9. Merge Sector Information Back to FIQA Dataset**"
      ],
      "metadata": {
        "id": "SsxfEgZ1sh5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths\n",
        "base_path = \"/content/drive/My Drive/P2/\"\n",
        "fiqa_path = base_path + \"fiqa_1.csv\"\n",
        "sector_path = base_path + \"final_ticker_sector3.csv\"\n",
        "output_path = base_path + \"fiqa_standardized.csv\"\n",
        "\n",
        "# Load datasets\n",
        "print(\"Loading datasets...\")\n",
        "df_fiqa = pd.read_csv(fiqa_path)\n",
        "df_sector = pd.read_csv(sector_path)\n",
        "\n",
        "print(f\"FIQA dataset shape: {df_fiqa.shape}\")\n",
        "print(f\"Sector mapping shape: {df_sector.shape}\")"
      ],
      "metadata": {
        "id": "-k8NL651skjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 10. Standardize Keys and Perform Merge**"
      ],
      "metadata": {
        "id": "YxQr9QxVsn34"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize keys for merge\n",
        "df_fiqa[\"target\"] = df_fiqa[\"target\"].astype(str).str.strip().str.upper()\n",
        "df_sector[\"ticker\"] = df_sector[\"ticker\"].astype(str).str.strip().str.upper()\n",
        "\n",
        "# Left join sector information to FIQA data\n",
        "df_merged = df_fiqa.merge(\n",
        "    df_sector[['ticker', 'sector']],\n",
        "    left_on=\"target\",\n",
        "    right_on=\"ticker\",\n",
        "    how=\"left\"\n",
        ")\n",
        "\n",
        "# Remove redundant ticker column\n",
        "if 'ticker' in df_merged.columns:\n",
        "    df_merged = df_merged.drop(columns=['ticker'])"
      ],
      "metadata": {
        "id": "5PsnRgWasmGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 11. Final Validation and Save Standardized Dataset**"
      ],
      "metadata": {
        "id": "c3k6KVjKsrru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing sector values after merge\n",
        "missing_rows = df_merged[df_merged['sector'].isna()]\n",
        "missing_count = len(missing_rows)\n",
        "\n",
        "if missing_count > 0:\n",
        "    print(f\"Warning: {missing_count} rows still missing sector information.\")\n",
        "\n",
        "    missing_tickers = missing_rows['target'].unique().tolist()\n",
        "    print(\"Tickers with missing sector:\")\n",
        "    for t in missing_tickers:\n",
        "        print(\" -\", t)\n",
        "else:\n",
        "    print(\"All records successfully matched with sector information.\")\n",
        "\n",
        "# Add ID column if not present\n",
        "if 'id' not in df_merged.columns:\n",
        "    df_merged.insert(0, 'id', range(len(df_merged)))\n",
        "\n",
        "# Rename sentence column to headline for prompt usage\n",
        "if 'headline' not in df_merged.columns and 'sentence' in df_merged.columns:\n",
        "    df_merged.rename(columns={'sentence': 'headline'}, inplace=True)\n",
        "\n",
        "# Save final standardized FIQA dataset\n",
        "df_merged.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"\\nFinal standardized dataset saved to:\")\n",
        "print(output_path)\n",
        "\n",
        "print(\"\\nPreview of first 5 rows:\")\n",
        "print(df_merged[['id', 'target', 'sector', 'label']].head())"
      ],
      "metadata": {
        "id": "lES7sHWJsseP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FIQA Experiment**"
      ],
      "metadata": {
        "id": "YTL55H59tZfo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 1. Environment Setup and Dependencies**"
      ],
      "metadata": {
        "id": "mdtT_t0xvLxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU google-genai tqdm pandas\n",
        "\n",
        "# Colab-ready pipeline: sample run followed by batch run for FIQA with 9 prompts\n",
        "# Notes:\n",
        "# 1) The API key will be entered manually in Colab and is not stored in the code\n",
        "# 2) A small sample is executed first before running the full dataset\n",
        "# 3) Results are written incrementally to CSV to avoid data loss from interruptions\n",
        "# 4) Concurrency, batch size, and retry behavior are configurable\n"
      ],
      "metadata": {
        "id": "gdlTNLfXvOOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 2. Imports and Global Configuration**"
      ],
      "metadata": {
        "id": "DXCrT3QrvSN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import math\n",
        "import json\n",
        "import csv\n",
        "import traceback\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from functools import partial\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "# Model configuration\n",
        "MODEL_NAME = \"models/gemini-2.5-flash\"\n",
        "\n",
        "# Base directory for input and output files\n",
        "BASE_PATH = \"/content/drive/My Drive/P2/\"\n",
        "\n",
        "# Input dataset (FIQA after standardization and sector injection)\n",
        "FIQA_PATH = BASE_PATH + \"fiqa_standardized.csv\"\n",
        "\n",
        "# Output files\n",
        "OUTPUT_CSV = BASE_PATH + \"fiqa_results.csv\"\n",
        "SAMPLE_OUTPUT_CSV = BASE_PATH + \"fiqa_results_sample.csv\""
      ],
      "metadata": {
        "id": "AnyLZKTWvQAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 3. Runtime Control Parameters**"
      ],
      "metadata": {
        "id": "A_aWFhKbvWMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Runtime control parameters\n",
        "SAMPLE_SIZE = 50           # Number of samples for initial test run\n",
        "BATCH_SIZE = 100           # Batch size for full dataset execution\n",
        "MAX_WORKERS = 6            # Number of concurrent workers\n",
        "MAX_RETRIES = 4            # Maximum retries per API call\n",
        "INITIAL_BACKOFF = 1.0      # Initial backoff time for retries (seconds)\n",
        "\n",
        "# Reference cost for paid tier (used for estimation only)\n",
        "PAID_INPUT_PRICE_PER_M = 0.50  # USD per 1M input tokens"
      ],
      "metadata": {
        "id": "fMNc7PervXlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 4. Prompt Definitions (9 Prompt Strategies)**"
      ],
      "metadata": {
        "id": "VVHfkFEyvawu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt templates used in the experiment\n",
        "PROMPTS = {\n",
        "    # Zero-Shot prompts\n",
        "    \"ZS-1\": \"Evaluate the sentiment conveyed by the headline with respect to {target} from an investment perspective. Employ a three-tier scale: (-1) for Negative, (0) for Neutral, and (+1) for Positive. Assign Neutral if the headline is vague regarding {target}.\\nConstraint: Answer with exactly one word: Positive, Negative, or Neutral.\",\n",
        "    \"ZS-2\": \"Given the news related to the {sector} industry, classify the sentiment as Positive, Negative, or Neutral, based on the headline: \\\"{headline}\\\".\\nConstraint: Answer with exactly one word: Positive, Negative, or Neutral.\",\n",
        "    \"ZS-3\": \"Act as a sentiment analysis model trained on financial news headlines. Classify the sentiment of the headline: \\\"{headline}\\\".\\nConstraint: Answer with exactly one word: Positive, Negative, or Neutral.\",\n",
        "\n",
        "    # Role-Play prompts\n",
        "    \"RP-1\": \"Act as an expert at stock trading holding {target}. Based only on the headline \\\"{headline}\\\", will you buy, sell or hold {target} in the short term?\\nConstraint: Answer with exactly one word. Return 'Positive' for buy, 'Negative' for sell, or 'Neutral' for hold.\",\n",
        "    \"RP-2\": \"Consider like an institutional investor, focusing on long-term, fundamental effects. Classify the sentiment of the following message regarding {target}: \\\"{headline}\\\".\\nConstraint: Answer with exactly one word: Positive, Negative, or Neutral.\",\n",
        "    \"RP-3\": \"Act as a financial expert. Classify the sentiment for {target} based only on the headline \\\"{headline}\\\".\\nConstraint: Answer with exactly one word: Positive, Negative, or Neutral.\",\n",
        "\n",
        "    # Chain-of-Thought prompts\n",
        "    \"CoT-1\": \"I will offer you a news headline regarding {target}: \\\"{headline}\\\".\\nPlease think step by step:\\n1. Analyze the rationale and potential impact on the stock price.\\n2. Identify the sentiment.\\n\\nConstraint: Return your response in this specific format:\\nRationale: [Your reasoning]\\nSentiment: [Positive, Negative, or Neutral]\",\n",
        "    \"CoT-2\": \"Consider this message: \\\"{headline}\\\".\\nStep 1: Identify any irrealis mood (uncertainty) or rhetorics (sarcasm, negative assertion) used in the text.\\nStep 2: Based on Step 1, determine the sentiment regarding {target}.\\n\\nConstraint: Return your response in this specific format:\\nAnalysis: [Your analysis]\\nSentiment: [Positive, Negative, or Neutral]\",\n",
        "    \"CoT-3\": \"Classify the sentiment of this news headline regarding {target}: \\\"{headline}\\\".\\nLet's think step by step to determine if it is Positive, Negative, or Neutral.\\n\\nConstraint: At the end of your response, output the label in this format:\\nSentiment: [Label]\"\n",
        "}"
      ],
      "metadata": {
        "id": "78jImPoUvdmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 5. API Key Input and Client Initialization**"
      ],
      "metadata": {
        "id": "lz06aqdJvfXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "# Request API key securely via input\n",
        "api_key = input(\"Enter your Google GENAI API Key: \").strip()\n",
        "client = genai.Client(api_key=api_key)"
      ],
      "metadata": {
        "id": "qcXqub-Ovg2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 6. Data Loading and Input Standardization**"
      ],
      "metadata": {
        "id": "2o_4GOMhx3Gc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(FIQA_PATH)\n",
        "\n",
        "# Standardize target / ticker format\n",
        "df[\"target\"] = df[\"target\"].astype(str).str.strip().str.upper()\n",
        "\n",
        "# Ensure a unified headline column\n",
        "if \"headline\" not in df.columns and \"sentence\" in df.columns:\n",
        "    df.rename(columns={\"sentence\": \"headline\"}, inplace=True)\n",
        "\n",
        "# Clean headline text\n",
        "df[\"headline\"] = df[\"headline\"].astype(str).str.strip()\n",
        "\n",
        "print(f\"Data loading completed: {len(df)} rows\")"
      ],
      "metadata": {
        "id": "nw2KIGWhx3Xk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample Run"
      ],
      "metadata": {
        "id": "WqRmCcPkvi6m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 1. Response Parsing Function**"
      ],
      "metadata": {
        "id": "HZXIMWUc0iBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function: parse the model's raw response into pos / neg / neu\n",
        "def clean_response_text(raw_text):\n",
        "    if raw_text is None:\n",
        "        return \"unknown\"\n",
        "    txt = str(raw_text).strip().lower()\n",
        "    if \"positive\" in txt:\n",
        "        return \"pos\"\n",
        "    if \"negative\" in txt:\n",
        "        return \"neg\"\n",
        "    if \"neutral\" in txt:\n",
        "        return \"neu\"\n",
        "    if \"bull\" in txt or \"buy\" in txt or \"+1\" in txt:\n",
        "        return \"pos\"\n",
        "    if \"bear\" in txt or \"sell\" in txt or \"-1\" in txt:\n",
        "        return \"neg\"\n",
        "    return \"unknown\""
      ],
      "metadata": {
        "id": "gwcfo2n50Ny1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 2. Model Call with Retry (No Token Tracking)**"
      ],
      "metadata": {
        "id": "pgvku2mH2sTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the model with retry logic (no token tracking)\n",
        "def call_model(prompt_text, model_name=MODEL_NAME, max_retries=MAX_RETRIES):\n",
        "    result = {\"raw_text\": None, \"success\": False}\n",
        "\n",
        "    backoff = INITIAL_BACKOFF\n",
        "    for attempt in range(1, max_retries + 1):\n",
        "        try:\n",
        "            response = client.models.generate_content(\n",
        "                model=model_name,\n",
        "                contents=prompt_text\n",
        "            )\n",
        "\n",
        "            # Extract raw text (compatible with different SDK response formats)\n",
        "            raw = None\n",
        "            if hasattr(response, \"output\") and response.output:\n",
        "                try:\n",
        "                    raw = \"\"\n",
        "                    for item in response.output:\n",
        "                        if isinstance(item, dict) and \"content\" in item:\n",
        "                            for c in item[\"content\"]:\n",
        "                                if isinstance(c, dict) and \"text\" in c:\n",
        "                                    raw += c[\"text\"]\n",
        "                                elif isinstance(c, str):\n",
        "                                    raw += c\n",
        "                        elif isinstance(item, str):\n",
        "                            raw += item\n",
        "                except Exception:\n",
        "                    raw = str(response)\n",
        "\n",
        "            elif hasattr(response, \"output_text\"):\n",
        "                raw = response.output_text\n",
        "\n",
        "            elif hasattr(response, \"text\"):\n",
        "                raw = response.text\n",
        "\n",
        "            else:\n",
        "                raw = str(response)\n",
        "\n",
        "            result[\"raw_text\"] = raw\n",
        "            result[\"success\"] = True\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[Attempt {attempt}] Call failed: {str(e)}. Retrying after {backoff}s...\")\n",
        "            traceback.print_exc()\n",
        "            time.sleep(backoff)\n",
        "            backoff *= 2\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "ibT_nKCj2mcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 3. Safe Prompt Formatting**"
      ],
      "metadata": {
        "id": "BjQFv-c32vWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Safely format prompt templates to prevent runtime failures\n",
        "def safe_format_prompt(template, headline, target, sector):\n",
        "    \"\"\"\n",
        "    Safely format the prompt:\n",
        "    1) If the template does not contain a {headline} placeholder, append it\n",
        "    2) Perform formatting in a single final step\n",
        "    \"\"\"\n",
        "    # Check for missing placeholder\n",
        "    if \"{headline}\" not in template:\n",
        "        template = template.rstrip() + '\\nHeadline: \"{headline}\"'\n",
        "\n",
        "    # Perform final formatting\n",
        "    try:\n",
        "        prompt_text = template.format(\n",
        "            headline=headline,\n",
        "            target=target,\n",
        "            sector=sector\n",
        "        )\n",
        "    except Exception:\n",
        "        # Minimal fallback: concatenate headline without raising errors or printing logs\n",
        "        prompt_text = f\"{template}\\nHeadline: {headline}\"\n",
        "\n",
        "    return prompt_text"
      ],
      "metadata": {
        "id": "9vMBjFRK22gz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 4. Single-Task Processing (One Result Row)**"
      ],
      "metadata": {
        "id": "BYzfLOxr20jC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Process one inference task and return one result row for CSV writing\n",
        "def process_one(item):\n",
        "    \"\"\"\n",
        "    item: dict with keys: id, headline, target, sector, prompt_id, prompt_template\n",
        "    Returns one result row as a dict for CSV output.\n",
        "    \"\"\"\n",
        "    # Safely format the prompt\n",
        "    prompt_text = safe_format_prompt(\n",
        "        item[\"prompt_template\"],\n",
        "        headline=item[\"headline\"],\n",
        "        target=item[\"target\"],\n",
        "        sector=item.get(\"sector\", \"Finance\")\n",
        "    )\n",
        "\n",
        "    # Call the model\n",
        "    call_res = call_model(prompt_text)\n",
        "    raw = call_res[\"raw_text\"]\n",
        "\n",
        "    # Parse the response\n",
        "    label = clean_response_text(raw)\n",
        "\n",
        "    return {\n",
        "        \"id\": item.get(\"id\"),\n",
        "        \"prompt_id\": item.get(\"prompt_id\"),\n",
        "        \"headline\": item[\"headline\"],\n",
        "        \"target\": item[\"target\"],\n",
        "        \"sector\": item.get(\"sector\", \"\"),\n",
        "        \"prompt_text\": prompt_text,\n",
        "        \"raw_response\": raw,\n",
        "        \"parsed_label\": label,\n",
        "        \"success\": call_res[\"success\"]\n",
        "    }"
      ],
      "metadata": {
        "id": "46RhF8dA22sd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 5. Parallel Execution and Incremental CSV Writing**"
      ],
      "metadata": {
        "id": "PErqHqbA2_Jh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run tasks in parallel and append results to CSV (no token tracking)\n",
        "def run_tasks(df_tasks, out_csv, max_workers=MAX_WORKERS, show_progress=True):\n",
        "    header = [\n",
        "        \"id\",\"prompt_id\",\"headline\",\"target\",\"sector\",\n",
        "        \"prompt_text\",\"raw_response\",\"parsed_label\",\"success\"\n",
        "    ]\n",
        "\n",
        "    if not os.path.exists(out_csv):\n",
        "        with open(out_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "            csv.writer(f).writerow(header)\n",
        "\n",
        "    total = len(df_tasks)\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=max_workers) as ex:\n",
        "        futures = []\n",
        "        for _, row in df_tasks.iterrows():\n",
        "            item = {\n",
        "                \"id\": int(row[\"id\"]),\n",
        "                \"headline\": row[\"headline\"],\n",
        "                \"target\": row[\"target\"],\n",
        "                \"sector\": row.get(\"sector\", \"\"),\n",
        "                \"prompt_id\": row[\"prompt_id\"],\n",
        "                \"prompt_template\": row[\"prompt_template\"]\n",
        "            }\n",
        "            futures.append(ex.submit(process_one, item))\n",
        "\n",
        "        pbar = tqdm(total=len(futures))\n",
        "        for fut in as_completed(futures):\n",
        "            res = fut.result()\n",
        "            with open(out_csv, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "                csv.writer(f).writerow([res.get(c,\"\") for c in header])\n",
        "            pbar.update(1)\n",
        "        pbar.close()"
      ],
      "metadata": {
        "id": "MmKHsyT12-4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 6. Task Construction (News × Prompts)**"
      ],
      "metadata": {
        "id": "Cy4bO1PQ3Cof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the task list by expanding each news item across all prompt templates\n",
        "def build_task_df(sub_df):\n",
        "    rows = []\n",
        "    for _, r in sub_df.iterrows():\n",
        "        for pid, template in PROMPTS.items():\n",
        "            rows.append({\n",
        "                \"id\": int(r.get(\"id\", \"\")),\n",
        "                \"headline\": r[\"headline\"],\n",
        "                \"target\": r[\"target\"],\n",
        "                \"sector\": r.get(\"sector\",\"\"),\n",
        "                \"prompt_id\": pid,\n",
        "                \"prompt_template\": template\n",
        "            })\n",
        "    return pd.DataFrame(rows)\n"
      ],
      "metadata": {
        "id": "f2CAh3zN3GcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 7. Sample Run Execution**"
      ],
      "metadata": {
        "id": "tO0mw-uY3Is8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_df = df.sample(SAMPLE_SIZE, random_state=42)\n",
        "sample_tasks = build_task_df(sample_df)\n",
        "\n",
        "print(\"Starting sample run...\")\n",
        "run_tasks(sample_tasks, SAMPLE_OUTPUT_CSV)\n",
        "print(\"Sample run completed. Please review:\", SAMPLE_OUTPUT_CSV)"
      ],
      "metadata": {
        "id": "I-RX3muh3LUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Full Run**"
      ],
      "metadata": {
        "id": "sLPd46l93Oia"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Full-Scale Inference with Batch Execution**"
      ],
      "metadata": {
        "id": "jY0YWvt43RDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Full run (batch execution)\n",
        "def full_run(confirm=False):\n",
        "    if not confirm:\n",
        "        print(\n",
        "            \"Please confirm the sample results first. \"\n",
        "            \"Call full_run(confirm=True) to start the full-scale run.\"\n",
        "        )\n",
        "        return\n",
        "\n",
        "    # Ensure an id column exists in the full dataset\n",
        "    full_df = df.copy().reset_index(drop=True)\n",
        "    if \"id\" not in full_df.columns:\n",
        "        full_df.insert(0, \"id\", range(len(full_df)))\n",
        "\n",
        "    # Build the full task dataframe\n",
        "    tasks_df = build_task_df(full_df)\n",
        "    print(\n",
        "        f\"Total tasks: {len(tasks_df)} \"\n",
        "        f\"(news {len(full_df)} × prompts {len(PROMPTS)})\"\n",
        "    )\n",
        "\n",
        "    # Split execution into batches based on news count (not task count)\n",
        "    news_indices = list(range(0, len(full_df), BATCH_SIZE))\n",
        "    batch_count = len(news_indices)\n",
        "    print(\n",
        "        f\"Execution will be split into {batch_count} batches, \"\n",
        "        f\"each containing up to {BATCH_SIZE} news items \"\n",
        "        f\"(tasks per batch = news_in_batch × {len(PROMPTS)})\"\n",
        "    )\n",
        "\n",
        "    for i, start in enumerate(news_indices):\n",
        "        end = min(start + BATCH_SIZE, len(full_df))\n",
        "        sub_news = full_df.iloc[start:end]\n",
        "        sub_tasks = build_task_df(sub_news)\n",
        "\n",
        "        # Append all batch results to the same output CSV\n",
        "        out_csv_batch = OUTPUT_CSV\n",
        "\n",
        "        print(\n",
        "            f\"\\nStarting batch {i + 1}/{batch_count}: \"\n",
        "            f\"processing news {start} to {end - 1} \"\n",
        "            f\"(tasks {len(sub_tasks)})\"\n",
        "        )\n",
        "\n",
        "        run_tasks(sub_tasks, out_csv_batch, max_workers=MAX_WORKERS)\n",
        "\n",
        "        print(\n",
        "            f\"Batch {i + 1} completed. \"\n",
        "            f\"Results appended to {out_csv_batch}\"\n",
        "        )\n",
        "\n",
        "        # Short pause between batches to reduce rate-limit risk\n",
        "        time.sleep(4)\n",
        "\n",
        "    print(\"Full-scale run completed. Results saved to:\", OUTPUT_CSV)"
      ],
      "metadata": {
        "id": "WlViWF6O3gzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Full Run Trigger***"
      ],
      "metadata": {
        "id": "cLZmeFks3r0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_run(confirm=True)"
      ],
      "metadata": {
        "id": "pYPqy-163t0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FIQA Evaluation"
      ],
      "metadata": {
        "id": "rsSpdtpt-o8y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 1. Imports**"
      ],
      "metadata": {
        "id": "9knVJnSw-up3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import os\n"
      ],
      "metadata": {
        "id": "LKhTzovW-xMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 2. File Path Configuration**"
      ],
      "metadata": {
        "id": "losaBaY3-0qZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = \"/content/drive/My Drive/P2/\"\n",
        "result_file = base_path + \"fiqa_results.csv\"              # Model inference outputs\n",
        "ground_truth_file = base_path + \"fiqa_standardized.csv\"   # Ground truth labels\n",
        "output_file = base_path + \"fiqa_metrics_summary.csv\"      # Metrics summary output"
      ],
      "metadata": {
        "id": "HAW357DZ-296"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 3. Load Data and Merge with Ground Truth Labels**"
      ],
      "metadata": {
        "id": "1SwbXfs7-68H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(result_file) or not os.path.exists(ground_truth_file):\n",
        "    print(\"Error: File not found. Please check your paths.\")\n",
        "else:\n",
        "    df_res = pd.read_csv(result_file)\n",
        "    df_gold = pd.read_csv(ground_truth_file)\n",
        "\n",
        "    print(f\"Result file rows: {len(df_res)}\")\n",
        "    print(f\"Ground truth rows: {len(df_gold)}\")\n",
        "\n",
        "    # Ensure consistent id data type for merging\n",
        "    df_res['id'] = df_res['id'].astype(int)\n",
        "    df_gold['id'] = df_gold['id'].astype(int)\n",
        "\n",
        "    # Merge ground truth label (column name fixed as 'label' in the source file)\n",
        "    df_final = pd.merge(df_res, df_gold[['id', 'label']], on='id', how='inner')\n",
        "    df_final.rename(columns={'label': 'gold_label'}, inplace=True)"
      ],
      "metadata": {
        "id": "bq10JPp4-8zM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 4. Label Cleaning and Alignment**"
      ],
      "metadata": {
        "id": "CeH1w9O3--xR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    # Standard label mapping (to support multiple formats)\n",
        "    label_map = {\n",
        "        'pos': 'Positive', 'positive': 'Positive',\n",
        "        'neg': 'Negative', 'negative': 'Negative',\n",
        "        'neu': 'Neutral',  'neutral': 'Neutral'\n",
        "    }\n",
        "\n",
        "    # Normalize predictions and ground truth labels\n",
        "    df_final['pred_clean'] = df_final['parsed_label'].astype(str).str.lower().map(label_map)\n",
        "    df_final['gold_clean'] = df_final['gold_label'].astype(str).str.lower().map(label_map)\n",
        "\n",
        "    # Remove rows that cannot be evaluated\n",
        "    df_clean = df_final.dropna(subset=['pred_clean', 'gold_clean'])\n",
        "\n",
        "    print(\n",
        "        f\"Valid evaluation samples after cleaning: {len(df_clean)} \"\n",
        "        f\"(dropped {len(df_final) - len(df_clean)} invalid rows)\"\n",
        "    )"
      ],
      "metadata": {
        "id": "3L_2Fd14_Alt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 5. Compute Metrics per Prompt (Accuracy, Precision, Recall, F1)**"
      ],
      "metadata": {
        "id": "2Spzmd8j_DZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    metrics_data = []\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"{'Prompt ID':<12} | {'Strategy':<10} | {'Accuracy':<10} | {'Precision':<10} | {'Recall':<10} | {'F1-Score':<10}\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Compute metrics grouped by prompt_id\n",
        "    for pid, group in df_clean.groupby('prompt_id'):\n",
        "        y_true = group['gold_clean']\n",
        "        y_pred = group['pred_clean']\n",
        "\n",
        "        # Strategy type (ZS = Zero-Shot, RP = Role-Play, CoT = Chain-of-Thought)\n",
        "        strategy = pid.split('-')[0]\n",
        "\n",
        "        # Metrics\n",
        "        acc = accuracy_score(y_true, y_pred)\n",
        "\n",
        "        # Weighted average is used because class distribution may be imbalanced\n",
        "        prec, rec, f1, _ = precision_recall_fscore_support(\n",
        "            y_true, y_pred, average='weighted', zero_division=0\n",
        "        )\n",
        "\n",
        "        metrics_data.append({\n",
        "            \"Prompt ID\": pid,\n",
        "            \"Strategy\": strategy,\n",
        "            \"Accuracy\": acc,\n",
        "            \"Precision\": prec,\n",
        "            \"Recall\": rec,\n",
        "            \"F1-Score\": f1\n",
        "        })\n",
        "\n",
        "        print(f\"{pid:<12} | {strategy:<10} | {acc:.4f}     | {prec:.4f}     | {rec:.4f}     | {f1:.4f}\")\n",
        "\n",
        "    print(\"=\"*80)"
      ],
      "metadata": {
        "id": "FRcKJYnG_Edl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 6. Save Results and Select the Best Prompt**"
      ],
      "metadata": {
        "id": "KKu83Ihx_GvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    df_metrics = pd.DataFrame(metrics_data)\n",
        "\n",
        "    # Rank prompts by F1-score\n",
        "    df_metrics = df_metrics.sort_values(by=\"F1-Score\", ascending=False)\n",
        "    df_metrics.to_csv(output_file, index=False)\n",
        "\n",
        "    print(f\"\\nMetrics summary saved to: {output_file}\")\n",
        "\n",
        "    # Select the best prompt\n",
        "    best_prompt = df_metrics.iloc[0]\n",
        "    print(\"\\nBest prompt selected\")\n",
        "    print(f\"ID: {best_prompt['Prompt ID']} ({best_prompt['Strategy']})\")\n",
        "    print(f\"F1-Score: {best_prompt['F1-Score']:.4f}\")\n",
        "    print(f\"Accuracy: {best_prompt['Accuracy']:.4f}\")"
      ],
      "metadata": {
        "id": "qilb3peO_InM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}